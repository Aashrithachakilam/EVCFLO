{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This notebook is used to extract data for charger types"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FOLLOW THE STEPS BELOW:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the code cell below, it will prompt you to enter the file location. The file location can be a raw.githubusercontent.com or right click on the dataset and copy the file path, copy path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Option 1 the url is given a value and is not \"None\" therefore the defined function \"load_data\" will not prompt the user to enter location.\n",
    "#url = \"https://raw.githubusercontent.com/Chameleon-company/EVCFLO/main/datasets/T1_2023/New_Zealand/NZ_Public_EV_Charger_Data_2023-04-28%2000_05_06NZDT.csv\"\n",
    "\n",
    "url=\"\"\n",
    "\n",
    "#Option 2 the above url is \"None\" unlike the example in Option 1. The following code is a defined function, when run it will prompt you to enter a file location.\n",
    "\n",
    "def load_data(url=None):\n",
    "    if url is None:\n",
    "        url = input(\"Please enter the URL to the CSV file: \")\n",
    "    \n",
    "    data = pd.read_csv(url)\n",
    "    return data\n",
    "\n",
    "data = load_data()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the code cell below, It will tell you the number of rows and columns as well as the column names and data types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This dataset has 391 rows and 24 columns.\n",
      "Columns & data types in the dataset:\n",
      "Unnamed: 0                      int64\n",
      "Location Name                  object\n",
      "Latitude                      float64\n",
      "Longitude                     float64\n",
      "Town                           object\n",
      "Postal Code                    object\n",
      "City                           object\n",
      "Address                        object\n",
      "Plugs_Type2                   float64\n",
      "Plugs_Three_Phase             float64\n",
      "Plugs_CHAdeMO                 float64\n",
      "Plugs_CCS/SAE                 float64\n",
      "Plugs_Tesla                   float64\n",
      "Plugs_J-1772                  float64\n",
      "Plugs_Caravan_Mains_Socket    float64\n",
      "Plugs_wall_AU/NZ              float64\n",
      "Power 1                       float64\n",
      "charging_stations             float64\n",
      "Nearby EVStations               int64\n",
      "Hospitals                       int64\n",
      "Parks                           int64\n",
      "Restaurants                     int64\n",
      "Malls                           int64\n",
      "Supermarkets                    int64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "#Return the number of rows and the number fo columns from the data entered in the cell above.\n",
    "\n",
    "print(\"This dataset has\", data.shape[0], \"rows and\", data.shape[1], \"columns.\")\n",
    "\n",
    "#Return the data types of each variable (column) from the data provided.\n",
    "\n",
    "print(\"Columns & data types in the dataset:\")\n",
    "print(data.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OPTION 1: single column for values = charger type name"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the code cell below, it will prompt you to enter the column for latitude, longitude and charger type. use the list above to pick the correct columns or open the CSV file and find the names for the right columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Name of variable (column) representing Latitude\n",
    "latitude = input(\"Enter the column name for Latitude: \")\n",
    "\n",
    "#Name of variable (column) representing longitude\n",
    "longitude = input(\"Enter the column name for Longitude: \")\n",
    "\n",
    "#Name of variable (column) representing charger type\n",
    "charger_type = input(\"Enter the column name for Charger Type: \")\n",
    "\n",
    "#Create a new dataframe with the columns defined above\n",
    "new_df = pd.DataFrame(data, columns=[latitude, longitude, charger_type])\n",
    "\n",
    "#Rename this new columns to the following\n",
    "new_df = new_df.rename(columns={\n",
    "    latitude: \"Latitude\",\n",
    "    longitude: \"Longitude\",\n",
    "    charger_type: \"charger_type\"\n",
    "})\n",
    "\n",
    "#Return the number of rows and the number fo columns from the data entered in the cell above.\n",
    "print(\"This dataset has\", new_df.shape[0], \"rows and\", new_df.shape[1], \"columns.\")\n",
    "\n",
    "\n",
    "#Return the data types of each variable (column) from the data provided.\n",
    "print(\"Columns & data types in the dataset:\")\n",
    "print(new_df.dtypes)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cell below can be used if you would like to create a new csv file to store the new data to, otherwise the code cell after will ask for the file you would like to add to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#new_df.to_csv(\"Paste location including a file name for your new csv, example: file location/blank.csv\", index=False)\n",
    "\n",
    "#save_location = input(\"Enter the save location for the blank CSV file: \")\n",
    "\n",
    "#new_df.to_csv(save_location, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OPTION 2: multiple columns for charger types, values = either charger or no charger for type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Latitude   Longitude charger_type\n",
      "8   -38.451339  145.240243       J-1772\n",
      "9   -37.804609  144.972702       J-1772\n",
      "11  -37.565285  144.893834       J-1772\n",
      "21  -38.398895  144.870509       J-1772\n",
      "23  -38.334999  144.986530       J-1772\n",
      "45  -37.704572  145.072077       J-1772\n",
      "71  -37.816254  144.954636       J-1772\n",
      "77  -37.831708  144.996522       J-1772\n",
      "79  -37.984494  145.216329       J-1772\n",
      "116 -37.909599  145.062347       J-1772\n",
      "139 -37.720262  144.895849       J-1772\n",
      "149 -37.884254  144.736465       J-1772\n",
      "166 -37.783420  145.126058       J-1772\n",
      "199 -16.923837  145.779668       J-1772\n",
      "200 -37.821232  144.967359       J-1772\n",
      "219 -37.812452  144.969535       J-1772\n",
      "235 -38.225341  144.328361       J-1772\n",
      "253 -38.340350  144.310815       J-1772\n",
      "272 -37.884233  144.734115       J-1772\n",
      "286 -37.816386  144.954776       J-1772\n",
      "307 -37.812113  144.970922       J-1772\n",
      "313 -37.723715  144.920974       J-1772\n",
      "316 -37.950648  145.080488       J-1772\n",
      "330 -37.958461  145.053615       J-1772\n",
      "350 -37.903260  145.095351       J-1772\n",
      "353 -37.822715  144.967670       J-1772\n",
      "354 -38.022421  145.213927       J-1772\n",
      "359 -38.010174  145.110226       J-1772\n",
      "364 -16.903674  145.761755       J-1772\n",
      "365 -37.815812  144.959512       J-1772\n",
      "369 -37.762252  145.168230       J-1772\n",
      "388 -37.803202  144.971757       J-1772\n",
      "Columns & data types in the dataset:\n",
      "Latitude        float64\n",
      "Longitude       float64\n",
      "charger_type     object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Name of variable (column) representing Latitude\n",
    "latitude = input(\"Enter the column name for Latitude: \")\n",
    "\n",
    "# Name of variable (column) representing longitude\n",
    "longitude = input(\"Enter the column name for Longitude: \")\n",
    "\n",
    "# Name of variable (column) representing charger_type\n",
    "charger_type = input(\"Enter the column name for Charger Type: \")\n",
    "\n",
    "# Name of charger_type\n",
    "charger_name = input(\"Enter the name of the Charger Type: \")\n",
    "\n",
    "# Create a new DataFrame with the specified columns\n",
    "new_df = pd.DataFrame(data, columns=[latitude, longitude, charger_type])\n",
    "\n",
    "# Rename the new columns\n",
    "new_df = new_df.rename(columns={\n",
    "    latitude: \"Latitude\",\n",
    "    longitude: \"Longitude\",\n",
    "    charger_type: \"charger_type\"\n",
    "})\n",
    "\n",
    "# Filter rows where \"charger_type\" is non-zero\n",
    "new_df = new_df[new_df[\"charger_type\"] != 0]\n",
    "\n",
    "# Replace non-zero values with the provided charger_name\n",
    "new_df[\"charger_type\"].replace(to_replace=new_df[\"charger_type\"].unique(), value=charger_name, inplace=True)\n",
    "\n",
    "# Print the filtered DataFrame\n",
    "print(new_df)\n",
    "\n",
    "#Return the data types of each variable (column) from the data provided.\n",
    "print(\"Columns & data types in the dataset:\")\n",
    "print(new_df.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## COMBINE AND SAVE!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the code cell below, It will prompt you to enter the file location of the CSV file that you would like to add the data to. This is the same process as the first code cell except we are picking the csv file that we want to add on to. It will add the data we collected using the pandas concat function, don't worry about accidently adding duplicates it will handle these!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicated rows before dropping:\n",
      "Empty DataFrame\n",
      "Columns: [Latitude, Longitude, charger_type]\n",
      "Index: []\n",
      "Duplicated rows after dropping:\n",
      "Empty DataFrame\n",
      "Columns: [Latitude, Longitude, charger_type]\n",
      "Index: []\n",
      "Number of duplicates before dropping: 0\n"
     ]
    }
   ],
   "source": [
    "# Enter the file location for the CSV file to ADD the new data to\n",
    "from_df_location = input(\"Enter the file location for the CSV file: \")\n",
    "\n",
    "# Load CSV to ADD data to\n",
    "from_df = pd.read_csv(from_df_location)\n",
    "\n",
    "# Concatenate new data to chosen CSV file\n",
    "combined_df = pd.concat([from_df, new_df], ignore_index=True)\n",
    "\n",
    "# Count the number of duplicate rows based on specified columns\n",
    "num_duplicates_before = combined_df.duplicated(subset=['Latitude', 'Longitude', 'charger_type'], keep=False).sum()\n",
    "\n",
    "# Find and print duplicated rows before dropping\n",
    "duplicated_rows_before = combined_df[combined_df.duplicated(subset=['Latitude', 'Longitude', 'charger_type'], keep=False)]\n",
    "print(\"Duplicated rows before dropping:\")\n",
    "print(duplicated_rows_before)\n",
    "\n",
    "# Drop duplicates\n",
    "combined_df.drop_duplicates(subset=['Latitude', 'Longitude', 'charger_type'], inplace=True)\n",
    "\n",
    "# Find and print duplicated rows after dropping\n",
    "duplicated_rows_after = combined_df[combined_df.duplicated(subset=['Latitude', 'Longitude', 'charger_type'], keep=False)]\n",
    "print(\"Duplicated rows after dropping:\")\n",
    "print(duplicated_rows_after)\n",
    "\n",
    "# Warning! Overwrite the existing dataset with the combined dataset\n",
    "combined_df.to_csv(from_df_location, index=False)\n",
    "\n",
    "print(f\"Number of duplicates before dropping: {num_duplicates_before}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the code cell below, We can now check to see the shape of the dataset that we have added more data to. Here we can track the number of station locations indicated by the number of rows! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This dataset has 526 rows and 3 columns.\n",
      "Columns & data types in the dataset:\n",
      "Latitude        float64\n",
      "Longitude       float64\n",
      "charger_type     object\n",
      "dtype: object\n",
      "    Latitude   Longitude charger_type\n",
      "0 -35.726720  145.659354        Type2\n",
      "1 -38.451339  145.240243        Type2\n",
      "2 -38.129308  144.345207        Type2\n",
      "3 -38.282256  145.125377        Type2\n",
      "4 -16.847662  145.695045        Type2\n"
     ]
    }
   ],
   "source": [
    "#This is now the CSV file with new data added to it\n",
    "print(\"This dataset has\", combined_df.shape[0], \"rows and\", combined_df.shape[1], \"columns.\")\n",
    "\n",
    "print(\"Columns & data types in the dataset:\")\n",
    "print(combined_df.dtypes)\n",
    "print(combined_df.head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
